{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3wjaiq1iNVC67qSx4pqnt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RoyMusango/edl-starter/blob/main/Recalage_final_IRPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxpLT0_lk2_Q"
      },
      "outputs": [],
      "source": [
        "# app.py\n",
        "import os\n",
        "import io\n",
        "import base64\n",
        "from datetime import datetime\n",
        "\n",
        "from flask import Flask, render_template, request, jsonify\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import cv2\n",
        "from skimage import exposure\n",
        "\n",
        "app = Flask(__name__, static_folder='static', template_folder='templates')\n",
        "\n",
        "UPLOAD_DIR = os.path.join(os.path.dirname(__file__), 'uploads')\n",
        "os.makedirs(UPLOAD_DIR, exist_ok=True)\n",
        "\n",
        "# ---------- Utilitaires I/O ----------\n",
        "def pil_to_u8_rgb(pil_img):\n",
        "    if pil_img.mode not in ('RGB', 'L'):\n",
        "        pil_img = pil_img.convert('RGB')\n",
        "    arr = np.array(pil_img)\n",
        "    if arr.ndim == 2:\n",
        "        return arr\n",
        "    if arr.shape[2] == 3:\n",
        "        return arr\n",
        "    return cv2.cvtColor(arr, cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "def imread_file_storage(fs):\n",
        "    img = Image.open(fs.stream)\n",
        "    img.load()\n",
        "    return pil_to_u8_rgb(img)\n",
        "\n",
        "def to_base64_png(img_u8):\n",
        "    if img_u8.ndim == 2:\n",
        "        pil = Image.fromarray(img_u8, mode='L')\n",
        "    else:\n",
        "        pil = Image.fromarray(img_u8, mode='RGB')\n",
        "    buf = io.BytesIO()\n",
        "    pil.save(buf, format='PNG')\n",
        "    return base64.b64encode(buf.getvalue()).decode('ascii')\n",
        "\n",
        "# ---------- Blocs de traitement (reprennent tes fonctions) ----------\n",
        "def _to_uint8(img):\n",
        "    from PIL import Image as _PILImage\n",
        "    if isinstance(img, _PILImage.Image):\n",
        "        if img.mode in ('RGBA', 'P'):\n",
        "            img = img.convert('RGBA').convert('RGB')\n",
        "        elif img.mode not in ('RGB', 'L'):\n",
        "            img = img.convert('RGB')\n",
        "        img = np.array(img)\n",
        "    if isinstance(img, (list, tuple)):\n",
        "        img = np.array(img)\n",
        "    if not isinstance(img, np.ndarray):\n",
        "        raise TypeError(\"Format d'image non supporté.\")\n",
        "    if img.dtype == np.uint8:\n",
        "        return img\n",
        "    if img.dtype.kind == 'f':\n",
        "        img = img if img.max() > 1.0 else (img * 255.0)\n",
        "    else:\n",
        "        img = np.clip(img, 0, 255)\n",
        "    return img.astype(np.uint8)\n",
        "\n",
        "def _ensure_gray_u8(img):\n",
        "    g = _to_uint8(img)\n",
        "    if g.ndim == 3:\n",
        "        g = cv2.cvtColor(g, cv2.COLOR_RGB2GRAY)\n",
        "    return g\n",
        "\n",
        "def _img_shape_wh(img_u8):\n",
        "    h, w = img_u8.shape[:2]\n",
        "    return w, h\n",
        "\n",
        "def make_orb():\n",
        "    return cv2.ORB_create(\n",
        "        nfeatures=5000, scaleFactor=1.2, nlevels=8, edgeThreshold=19,\n",
        "        firstLevel=0, WTA_K=2, scoreType=cv2.ORB_HARRIS_SCORE,\n",
        "        patchSize=31, fastThreshold=12\n",
        "    )\n",
        "\n",
        "def detect_describe(gray_u8, orb=None):\n",
        "    if orb is None:\n",
        "        orb = make_orb()\n",
        "    kps, des = orb.detectAndCompute(gray_u8, None)\n",
        "    return kps or [], des\n",
        "\n",
        "def match_descriptors(des_ref, des_mov, ratio=0.75):\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)\n",
        "    if des_ref is None or des_mov is None:\n",
        "        return []\n",
        "    knn_rm = bf.knnMatch(des_ref, des_mov, k=2)\n",
        "    pre = [(m, n) for m, n in knn_rm if len([m, n]) == 2 and m.distance < ratio * n.distance]\n",
        "    pre = [m for m, _ in pre]\n",
        "    knn_mr = bf.knnMatch(des_mov, des_ref, k=2)\n",
        "    pre_rev = {}\n",
        "    for m, n in knn_mr:\n",
        "        if m.distance < ratio * n.distance:\n",
        "            pre_rev[(m.trainIdx, m.queryIdx)] = m.distance\n",
        "    sym = [m for m in pre if (m.queryIdx, m.trainIdx) in pre_rev]\n",
        "    sym.sort(key=lambda x: x.distance)\n",
        "    return sym\n",
        "\n",
        "def bucket_matches(kp_ref, kp_mov, matches, img_size, grid=(8, 8), max_per_cell=80):\n",
        "    if len(matches) == 0:\n",
        "        return []\n",
        "    w, h = img_size\n",
        "    gx, gy = grid\n",
        "    cell_w, cell_h = w / gx, h / gy\n",
        "    buckets = {(ix, iy): [] for ix in range(gx) for iy in range(gy)}\n",
        "    for m in matches:\n",
        "        x, y = kp_ref[m.queryIdx].pt\n",
        "        ix = min(gx - 1, max(0, int(x // cell_w)))\n",
        "        iy = min(gy - 1, max(0, int(y // cell_h)))\n",
        "        buckets[(ix, iy)].append(m)\n",
        "    kept = []\n",
        "    for key in buckets:\n",
        "        cell = sorted(buckets[key], key=lambda mm: mm.distance)[:max_per_cell]\n",
        "        kept.extend(cell)\n",
        "    kept = sorted(kept, key=lambda m: m.distance)\n",
        "    return kept\n",
        "\n",
        "def _pts_from_matches(kp_ref, kp_mov, matches):\n",
        "    pts_ref = np.float32([kp_ref[m.queryIdx].pt for m in matches])\n",
        "    pts_mov = np.float32([kp_mov[m.trainIdx].pt for m in matches])\n",
        "    return pts_ref, pts_mov\n",
        "\n",
        "def _err_reproj_mean(pts_src, pts_dst, H, is_homography):\n",
        "    if is_homography:\n",
        "        pts_src_h = cv2.convertPointsToHomogeneous(pts_src)[:, 0, :]\n",
        "        proj_h = (H @ pts_src_h.T).T\n",
        "        proj = proj_h[:, :2] / proj_h[:, 2:3]\n",
        "    else:\n",
        "        proj = cv2.transform(pts_src.reshape(1, -1, 2), H).reshape(-1, 2)\n",
        "    return np.linalg.norm(proj - pts_dst, axis=1).mean()\n",
        "\n",
        "def _estimate_models_and_score(ref_gray, mov_gray, kp_ref, kp_mov, matches, img_size, rth=3.0):\n",
        "    results = []\n",
        "    if len(matches) < 8:\n",
        "        return results\n",
        "    pts_ref, pts_mov = _pts_from_matches(kp_ref, kp_mov, matches)\n",
        "\n",
        "    A_sim, inl_sim = cv2.estimateAffinePartial2D(pts_mov, pts_ref, method=cv2.RANSAC,\n",
        "                                                 ransacReprojThreshold=rth, confidence=0.999, maxIters=5000)\n",
        "    if A_sim is not None and inl_sim is not None:\n",
        "        inliers = int(inl_sim.ravel().sum()); ratio = inliers / max(1, len(matches))\n",
        "        err = _err_reproj_mean(pts_mov[inl_sim.ravel() == 1], pts_ref[inl_sim.ravel() == 1], A_sim, is_homography=False) if inliers > 0 else 1e9\n",
        "        warped = cv2.warpAffine(mov_gray, A_sim, _img_shape_wh(ref_gray), flags=cv2.INTER_LINEAR)\n",
        "        results.append(dict(model_name='similarity', ok=inliers >= 6, inlier_ratio=ratio, err_px=err,\n",
        "                            warped=warped, H=A_sim, is_h=False))\n",
        "\n",
        "    A_aff, inl_aff = cv2.estimateAffine2D(pts_mov, pts_ref, method=cv2.RANSAC,\n",
        "                                          ransacReprojThreshold=rth, confidence=0.999, maxIters=5000)\n",
        "    if A_aff is not None and inl_aff is not None:\n",
        "        inliers = int(inl_aff.ravel().sum()); ratio = inliers / max(1, len(matches))\n",
        "        err = _err_reproj_mean(pts_mov[inl_aff.ravel() == 1], pts_ref[inl_aff.ravel() == 1], A_aff, is_homography=False) if inliers > 0 else 1e9\n",
        "        warped = cv2.warpAffine(mov_gray, A_aff, _img_shape_wh(ref_gray), flags=cv2.INTER_LINEAR)\n",
        "        results.append(dict(model_name='affine', ok=inliers >= 6, inlier_ratio=ratio, err_px=err,\n",
        "                            warped=warped, H=A_aff, is_h=False))\n",
        "\n",
        "    H, mask = cv2.findHomography(pts_mov, pts_ref, method=cv2.RANSAC, ransacReprojThreshold=max(rth, 4.0), maxIters=5000, confidence=0.999)\n",
        "    if H is not None and mask is not None:\n",
        "        inliers = int(mask.ravel().sum()); ratio = inliers / max(1, len(matches))\n",
        "        err = _err_reproj_mean(pts_mov[mask.ravel() == 1], pts_ref[mask.ravel() == 1], H, is_homography=True) if inliers > 0 else 1e9\n",
        "        warped = cv2.warpPerspective(mov_gray, H, _img_shape_wh(ref_gray), flags=cv2.INTER_LINEAR)\n",
        "        results.append(dict(model_name='homography', ok=inliers >= 10, inlier_ratio=ratio, err_px=err,\n",
        "                            warped=warped, H=H, is_h=True))\n",
        "    return results\n",
        "\n",
        "def votre_pipeline_orb_ransac(img_ref_gray_u8, img_mov_gray_u8, verbose=False):\n",
        "    orb = make_orb()\n",
        "    kp_ref, des_ref = detect_describe(img_ref_gray_u8, orb)\n",
        "    kp_mov, des_mov = detect_describe(img_mov_gray_u8, orb)\n",
        "    if des_ref is None or des_mov is None or len(kp_ref) < 8 or len(kp_mov) < 8:\n",
        "        return dict(ok=False, reason='peu_de_points', matches=[], kp_ref=kp_ref, kp_mov=kp_mov)\n",
        "    matches = match_descriptors(des_ref, des_mov, ratio=0.75)\n",
        "    matches = bucket_matches(kp_ref, kp_mov, matches, _img_shape_wh(img_ref_gray_u8), grid=(8, 8), max_per_cell=80)\n",
        "    matches = matches[:2000]\n",
        "    if len(matches) < 12:\n",
        "        return dict(ok=False, reason='trop_peu_de_matches', matches=matches, kp_ref=kp_ref, kp_mov=kp_mov)\n",
        "    model_results = _estimate_models_and_score(img_ref_gray_u8, img_mov_gray_u8, kp_ref, kp_mov, matches, _img_shape_wh(img_ref_gray_u8))\n",
        "    if not model_results:\n",
        "        return dict(ok=False, reason='estimation_impossible', matches=matches, kp_ref=kp_ref, kp_mov=kp_mov)\n",
        "    model_results.sort(key=lambda r: (-r['inlier_ratio'], r['err_px'], -len(matches)))\n",
        "    best = model_results[0]\n",
        "    return dict(ok=best['ok'], model_name=best['model_name'], inlier_ratio=float(best['inlier_ratio']),\n",
        "                err_px=float(best['err_px']), warped=best['warped'], H=best['H'], is_h=best['is_h'],\n",
        "                matches=matches, matches_count=len(matches), kp_ref=kp_ref, kp_mov=kp_mov)\n",
        "\n",
        "def approche_robuste_recalage(img_NB, img_color):\n",
        "    ref_rgb_u8 = _to_uint8(img_color)\n",
        "    ref_gray_u8 = cv2.cvtColor(ref_rgb_u8, cv2.COLOR_RGB2GRAY) if ref_rgb_u8.ndim == 3 else ref_rgb_u8\n",
        "    mov_gray_u8 = _ensure_gray_u8(img_NB)\n",
        "    # multi-variantes (CLAHE / blur)\n",
        "    def run(gray_ref, gray_mov):\n",
        "        return votre_pipeline_orb_ransac(gray_ref, gray_mov, verbose=False)\n",
        "    A = run(ref_gray_u8, mov_gray_u8)\n",
        "    clahe = cv2.createCLAHE(clipLimit=1.6, tileGridSize=(8, 8))\n",
        "    B = run(clahe.apply(ref_gray_u8), clahe.apply(mov_gray_u8))\n",
        "    C = run(cv2.GaussianBlur(ref_gray_u8, (3, 3), 0.6), cv2.GaussianBlur(mov_gray_u8, (3, 3), 0.6))\n",
        "    candidates = {'A': A, 'B': B, 'C': C}\n",
        "    def score(x): return (-x.get('inlier_ratio', 0.0), x.get('err_px', 1e9), -x.get('matches_count', 0))\n",
        "    best_key = sorted(candidates.keys(), key=lambda k: score(candidates[k]))[0]\n",
        "    return candidates[best_key]\n",
        "\n",
        "def adapter_histogramme(cible, reference):\n",
        "    return exposure.match_histograms(cible, reference)\n",
        "\n",
        "def normaliser_histogrammes(img_color, img_NB):\n",
        "    if img_color.ndim == 3:\n",
        "        img_color_gray = cv2.cvtColor(img_color, cv2.COLOR_RGB2GRAY)\n",
        "    else:\n",
        "        img_color_gray = img_color\n",
        "    img_NB_eq = exposure.equalize_hist(img_NB)\n",
        "    img_color_eq = exposure.equalize_hist(img_color_gray)\n",
        "    return img_NB_eq, img_color_eq\n",
        "\n",
        "\n",
        "def _norm01(x):\n",
        "    x = x.astype(np.float32)\n",
        "    mn, mx = x.min(), x.max()\n",
        "    if mx <= mn:\n",
        "        return np.zeros_like(x, dtype=np.float32)\n",
        "    return (x - mn) / (mx - mn)\n",
        "\n",
        "def _gauss(img, sigma):\n",
        "    k = max(3, int(6*sigma+1)//2*2+1)\n",
        "    return cv2.GaussianBlur(img, (k, k), sigma)\n",
        "\n",
        "def _grad_energy(gray_u8):\n",
        "    # Scharr = gradients stables\n",
        "    gx = cv2.Scharr(gray_u8, cv2.CV_32F, 1, 0)\n",
        "    gy = cv2.Scharr(gray_u8, cv2.CV_32F, 0, 1)\n",
        "    mag = np.sqrt(gx*gx + gy*gy)\n",
        "    return _norm01(mag)\n",
        "\n",
        "def _local_contrast(gray_u8, sigma=2.0):\n",
        "    f = gray_u8.astype(np.float32)/255.0\n",
        "    mu = _gauss(f, sigma)\n",
        "    mu2 = _gauss(f*f, sigma)\n",
        "    var = np.clip(mu2 - mu*mu, 0, 1)\n",
        "    std = np.sqrt(var)\n",
        "    return _norm01(std)\n",
        "\n",
        "def _build_pyramids(img, levels):\n",
        "    G = [img.astype(np.float32)]\n",
        "    for _ in range(levels-1):\n",
        "        G.append(cv2.pyrDown(G[-1]))\n",
        "    L = [G[-1]]\n",
        "    for i in range(levels-1, 0, -1):\n",
        "        up = cv2.pyrUp(G[i], dstsize=(G[i-1].shape[1], G[i-1].shape[0]))\n",
        "        L.append(G[i-1] - up)\n",
        "    L.reverse()\n",
        "    return G, L  # Gaussian, Laplacian\n",
        "\n",
        "def _blend_pyramids(LA, LB, GW):\n",
        "    # LA/LB: Laplaciennes, GW: gaussiennes de poids B (même nb de niveaux)\n",
        "    out = []\n",
        "    for lA, lB, gW in zip(LA, LB, GW):\n",
        "        W = gW.astype(np.float32)\n",
        "        out.append((1.0 - W) * lA + W * lB)\n",
        "    # reconstruction\n",
        "    res = out[-1]\n",
        "    for i in range(len(out)-2, -1, -1):\n",
        "        res = cv2.pyrUp(res, dstsize=(out[i].shape[1], out[i].shape[0])) + out[i]\n",
        "    return res\n",
        "\n",
        "def construire_superposition_robuste(img_color_matched, result_align, img_NB_norm_uint8,\n",
        "                                     prefer_nb_on_whites=True,\n",
        "                                     levels=4,\n",
        "                                     softness=1.6,\n",
        "                                     w_white=0.55, w_lowgrad=0.30, w_lowcont=0.15):\n",
        "    \"\"\"\n",
        "    Renvoie une image finale sans \"trous blancs\" en privilégiant NB alignée\n",
        "    là où la couleur normalisée est peu informative. Mélange multi‑résolution.\n",
        "    - prefer_nb_on_whites: si True, booste le poids NB sur zones très claires.\n",
        "    - levels: niveaux de pyramide (3-5 conseillé).\n",
        "    - softness: contrôle la pente (sigmoïde) de la carte poids.\n",
        "    - w_*: pondérations (doivent sommer ~1).\n",
        "    \"\"\"\n",
        "    base = _to_uint8(img_color_matched)\n",
        "    base_gray = cv2.cvtColor(base, cv2.COLOR_RGB2GRAY) if base.ndim == 3 else base\n",
        "\n",
        "    if result_align.get('ok') and result_align.get('warped') is not None:\n",
        "        nb_aligned = _to_uint8(result_align['warped'])\n",
        "    else:\n",
        "        nb_aligned = _to_uint8(img_NB_norm_uint8)\n",
        "\n",
        "    if nb_aligned.shape[:2] != base_gray.shape[:2]:\n",
        "        nb_aligned = cv2.resize(nb_aligned, (base_gray.shape[1], base_gray.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # 1) Cartes mesures\n",
        "    white = base_gray.astype(np.float32)/255.0                          # blancheur\n",
        "    grad  = _grad_energy(base_gray)                                     # énergie gradient\n",
        "    cont  = _local_contrast(base_gray, sigma=2.0)                       # contraste local\n",
        "\n",
        "    low_grad = 1.0 - grad                                              # faible structure\n",
        "    low_cont = 1.0 - cont\n",
        "\n",
        "    # 2) Carte de poids NB (où on veut remplacer par NB)\n",
        "    w_nb = w_white*white + w_lowgrad*low_grad + w_lowcont*low_cont\n",
        "    if not prefer_nb_on_whites:\n",
        "        w_nb = w_lowgrad*low_grad + w_lowcont*low_cont\n",
        "    w_nb = _norm01(w_nb)\n",
        "\n",
        "    # Douceur (sigmoïde) pour éviter des bords durs\n",
        "    w_nb = 1.0 / (1.0 + np.exp(-softness*(w_nb - 0.5)))\n",
        "\n",
        "    # 3) Lissage supplémentaire\n",
        "    w_nb = _gauss(w_nb, 1.2)\n",
        "    w_nb = np.clip(w_nb, 0.0, 1.0)\n",
        "\n",
        "    # 4) Mélange pyramidal (évite halos/joints)\n",
        "    A = base_gray.astype(np.float32)/255.0\n",
        "    B = nb_aligned.astype(np.float32)/255.0\n",
        "\n",
        "    # Pyramides\n",
        "    GA, LA = _build_pyramids(A, levels)\n",
        "    GB, LB = _build_pyramids(B, levels)\n",
        "    GW = []\n",
        "    g = w_nb.astype(np.float32)\n",
        "    for _ in range(levels):\n",
        "        GW.append(g)\n",
        "        g = cv2.pyrDown(g)\n",
        "\n",
        "    blended = _blend_pyramids(LA, LB, GW)\n",
        "    out = np.clip(blended*255.0, 0, 255).astype(np.uint8)\n",
        "    return out\n",
        "\n",
        "# Version simple, très rapide (fallback)\n",
        "def construire_superposition_adaptative(img_color_matched, result_align, img_NB_norm_uint8,\n",
        "                                        t_white=None, blur=5, alpha_min=0.1, alpha_max=0.9):\n",
        "    base = _to_uint8(img_color_matched)\n",
        "    base_gray = cv2.cvtColor(base, cv2.COLOR_RGB2GRAY) if base.ndim == 3 else base\n",
        "    nb_aligned = _to_uint8(result_align['warped']) if result_align.get('ok') and result_align.get('warped') is not None else _to_uint8(img_NB_norm_uint8)\n",
        "    if nb_aligned.shape[:2] != base_gray.shape[:2]:\n",
        "        nb_aligned = cv2.resize(nb_aligned, (base_gray.shape[1], base_gray.shape[0]), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "    # seuil automatique si non fourni (percentile 90)\n",
        "    if t_white is None:\n",
        "        t_white = int(np.percentile(base_gray, 90))\n",
        "\n",
        "    mask_white = (base_gray >= t_white).astype(np.float32)\n",
        "    mask_white = cv2.GaussianBlur(mask_white, (blur|1, blur|1), 0)\n",
        "    # poids NB fort sur blancs; sinon mix doux\n",
        "    alpha_map = alpha_min + (alpha_max - alpha_min) * mask_white\n",
        "    out = (1.0 - alpha_map) * base_gray.astype(np.float32) + alpha_map * nb_aligned.astype(np.float32)\n",
        "    return np.clip(out, 0, 255).astype(np.uint8)\n",
        "\n",
        "\n",
        "# FIN DE LA NOUVELLE FONCTION ------------------******************----------------------------***************************-----------------------------***************************----------------------------\n",
        "\n",
        "def resize_to(img, ref_shape_hw):\n",
        "    rh, rw = ref_shape_hw\n",
        "    if img.ndim == 2:\n",
        "        return cv2.resize(img, (rw, rh), interpolation=cv2.INTER_LINEAR)\n",
        "    else:\n",
        "        return cv2.resize(img, (rw, rh), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# ---------- Routes ----------\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.post('/upload')\n",
        "def upload_compat():\n",
        "    file = request.files.get('image')\n",
        "    if not file:\n",
        "        return \"Aucune image reçue\", 400\n",
        "    file.save(os.path.join(UPLOAD_DIR, file.filename))\n",
        "    return f\"Image {file.filename} uploadée avec succès\", 200\n",
        "\n",
        "@app.post('/uploads')\n",
        "def uploads_triplet():\n",
        "    try:\n",
        "        rgb = request.files.get('imageRGB')\n",
        "        nb = request.files.get('imageNB')\n",
        "        mask = request.files.get('Masque')  # optionnel\n",
        "\n",
        "        # Masque optionnel, on exige seulement RGB et NB\n",
        "        missing = [k for k, v in (('imageRGB', rgb), ('imageNB', nb)) if v is None]\n",
        "        if missing:\n",
        "            return jsonify(ok=False, error=f\"Champs manquants: {', '.join(missing)}\"), 400\n",
        "\n",
        "        # Sauvegarde brute\n",
        "        ts = datetime.now().strftime('%Y%m%d_%H%M%S_%f')\n",
        "        for prefix, f in (('rgb', rgb), ('nb', nb), ('mask', mask)):\n",
        "            if f:\n",
        "                f.save(os.path.join(UPLOAD_DIR, f\"{prefix}_{ts}_{f.filename}\"))\n",
        "\n",
        "        # Lecture\n",
        "        img_color = imread_file_storage(rgb)  # RGB uint8\n",
        "        img_nb_any = imread_file_storage(nb)\n",
        "        img_nb = img_nb_any if img_nb_any.ndim == 2 else cv2.cvtColor(img_nb_any, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "        # Normalisations\n",
        "        img_NB_norm_f, img_color_norm_gray_f = normaliser_histogrammes(img_color, img_nb)\n",
        "        nb_eq_u8 = (np.clip(img_NB_norm_f, 0, 1) * 255.0).astype(np.uint8)\n",
        "        color_gray_eq_u8 = (np.clip(img_color_norm_gray_f, 0, 1) * 255.0).astype(np.uint8)\n",
        "\n",
        "        # Adapter l’histo de la couleur (gris) vers la NB\n",
        "        img_color_matched_f = adapter_histogramme(color_gray_eq_u8.astype(np.float32) / 255.0,\n",
        "                                                  nb_eq_u8.astype(np.float32) / 255.0)\n",
        "        img_color_matched_u8 = (np.clip(img_color_matched_f, 0, 1) * 255.0).astype(np.uint8)\n",
        "\n",
        "        # Recalage NB -> couleur (référence = couleur originale)\n",
        "        result_align = approche_robuste_recalage(nb_eq_u8, img_color)\n",
        "        nb_aligned_u8 = _to_uint8(result_align['warped']) if result_align.get('ok') and result_align.get('warped') is not None else nb_eq_u8\n",
        "\n",
        "        # Superposition finale\n",
        "        # La ligne suivante est l'appel de l'overlay de superpositio avec l'ancienne fonction\n",
        "        \"\"\"\n",
        "        overlay_final_u8 = construire_superposition(img_color_matched_u8, result_align, nb_eq_u8, alpha=0.5)\n",
        "        \"\"\"\n",
        "\n",
        "        # UTILISATION DE LA NOUVELLE FONCTION --------------*********************-------------------***********\n",
        "        overlay_final_u8 = construire_superposition_robuste(\n",
        "        img_color_matched_u8, result_align, nb_eq_u8,\n",
        "        prefer_nb_on_whites=True, levels=4, softness=1.6,\n",
        "        w_white=0.55, w_lowgrad=0.30, w_lowcont=0.15)\n",
        "        # FIN D'UTILISATION DE LA NOUVELLE FONCTION --------------*********************-------------------***********\n",
        "\n",
        "        # Assurer TOUTES les images à la même taille (référence = img_color_matched_u8)\n",
        "        ref_h, ref_w = img_color_matched_u8.shape[:2]\n",
        "        ref_shape = (ref_h, ref_w)\n",
        "\n",
        "        original_color_rgb_u8 = resize_to(img_color, ref_shape)\n",
        "        original_nb_u8        = resize_to(img_nb, ref_shape)\n",
        "        color_norm_u8         = resize_to(img_color_matched_u8, ref_shape)        # gris (matched)\n",
        "        nb_norm_u8            = resize_to(nb_eq_u8, ref_shape)\n",
        "        nb_norm_aligned_u8    = resize_to(nb_aligned_u8, ref_shape)\n",
        "        overlay_final_u8      = resize_to(overlay_final_u8, ref_shape)\n",
        "\n",
        "        out = {\n",
        "            \"ok\": True,\n",
        "            \"model\": result_align.get('model_name', None),\n",
        "            \"inlier_ratio\": float(result_align.get('inlier_ratio', 0.0)),\n",
        "            \"err_px\": float(result_align.get('err_px', 0.0)),\n",
        "\n",
        "            # 5 images à taille uniforme\n",
        "            \"original_color_rgb_b64\": to_base64_png(original_color_rgb_u8),\n",
        "            \"original_nb_b64\":        to_base64_png(original_nb_u8),\n",
        "            \"color_normalized_b64\":   to_base64_png(color_norm_u8),\n",
        "            \"nb_norm_b64\":            to_base64_png(nb_norm_u8),\n",
        "            \"nb_norm_aligned_b64\":    to_base64_png(nb_norm_aligned_u8),\n",
        "            \"overlay_final_b64\":      to_base64_png(overlay_final_u8)\n",
        "        }\n",
        "        return jsonify(out), 200\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback; traceback.print_exc()\n",
        "        return jsonify(ok=False, error=str(e)), 500\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(host=\"127.0.0.1\", port=8000, debug=True)\n"
      ]
    }
  ]
}